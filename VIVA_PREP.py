#!/usr/bin/env python3
"""
ğŸŒ¿ Mango Disease Project - Viva Preparation & Quick Demo
Simple script to help you prepare for the viva presentation
"""

print("=" * 70)
print("ğŸŒ¿ MANGO LEAF DISEASE DETECTION - VIVA PREPARATION")
print("=" * 70)

# Project Overview
print("\nğŸ“Œ PROJECT OVERVIEW (30 seconds)")
print("-" * 70)
overview = """
This project builds an AI system to classify mango leaf diseases.

â€¢ Purpose: Help farmers diagnose leaf diseases quickly
â€¢ Model: Swin Transformer Tiny (transfer learning)
â€¢ Dataset: 4000 images, 8 disease classes
â€¢ Accuracy: 99.87% validation, 100% test
â€¢ Demo: Desktop GUI for real-time predictions
"""
print(overview)

# Dataset & Classes
print("\nğŸ“Š DATASET & CLASSES")
print("-" * 70)
classes = [
    "1. Anthracnose        - Fungal disease with dark lesions",
    "2. Bacterial Canker   - Water-soaked lesions with yellow halo",
    "3. Cutting Weevil     - Pest causing irregular holes",
    "4. Die Back           - Branch death from tip to base",
    "5. Gall Midge         - Abnormal leaf growths",
    "6. Healthy            - No disease detected",
    "7. Powdery Mildew     - White powdery coating",
    "8. Sooty Mould        - Black sooty coating"
]
for cls in classes:
    print(f"  {cls}")

# Model Architecture
print("\nğŸ—ï¸ MODEL ARCHITECTURE (45 seconds)")
print("-" * 70)
architecture = """
Backbone: SwinTransformerTiny224 (ImageNet pretrained)
â”œâ”€â”€ Input: 224Ã—224Ã—3 RGB image
â”œâ”€â”€ Swin-Tiny blocks with window attention
â””â”€â”€ Global Average Pooling

Head (Classification):
â”œâ”€â”€ Dense(512) + BatchNorm + Dropout(0.5)
â”œâ”€â”€ Dense(256) + BatchNorm + Dropout(0.4)
â”œâ”€â”€ Dense(128) + Dropout(0.3)
â””â”€â”€ Dense(8) + Softmax â†’ 8 disease probabilities

Total Parameters: ~28 million
"""
print(architecture)

# Training Strategy
print("\nğŸ“ˆ TRAINING STRATEGY (Two-Phase Training)")
print("-" * 70)
training = """
Phase 1: Head Training (30 epochs)
â”œâ”€â”€ Backbone: FROZEN (use pretrained features)
â”œâ”€â”€ Train: Only the classification head
â”œâ”€â”€ Optimizer: Adam (lr=1e-4)
â””â”€â”€ Result: ~90% accuracy

Phase 2: Fine-Tuning (30 epochs)
â”œâ”€â”€ Backbone: UNFROZEN (keep early layers frozen)
â”œâ”€â”€ Train: Entire model with low learning rate
â”œâ”€â”€ Optimizer: Adam (lr=5e-5)
â””â”€â”€ Result: 99.87% accuracy âœ…
"""
print(training)

# Hyperparameters
print("\nâš™ï¸ HYPERPARAMETERS")
print("-" * 70)
params = """
Image Size:              224Ã—224
Batch Size:              16
Epochs per Phase:        30
Validation Split:        80/20
Augmentation:            Flip, Rotate, Zoom, Contrast, Brightness
Optimizer:               Adam
Learning Rate (Ph1):     1e-4
Learning Rate (Ph2):     5e-5
Regularization:          L2(1e-4), Dropout, BatchNorm
Callbacks:               ReduceLROnPlateau, EarlyStopping
"""
print(params)

# Data Augmentation
print("\nğŸ¨ DATA AUGMENTATION (Why?)")
print("-" * 70)
augmentation = """
Applied to training data only (not validation/test):
âœ“ RandomFlip (horizontal & vertical) - Handles leaf orientation
âœ“ RandomRotation(0.2)              - Leaf angle variation
âœ“ RandomZoom(0.2)                  - Camera distance variation
âœ“ RandomContrast(0.2)              - Lighting conditions
âœ“ RandomBrightness(0.1)            - Brightness changes

Result: Model learns from diverse real-world variations
"""
print(augmentation)

# Performance Results
print("\nğŸ“Š FINAL RESULTS")
print("-" * 70)
results = """
Phase 1 (Frozen Backbone):
  Training Accuracy:   ~87%
  Validation Accuracy: ~85%

Phase 2 (Fine-tuning):
  Training Accuracy:   99.99%
  Validation Accuracy: 99.87% âœ…
  Test Accuracy:       100.0% âœ…
"""
print(results)

# GUI Features
print("\nğŸ–¥ï¸ GUI FEATURES (Desktop Application)")
print("-" * 70)
gui = """
Left Panel (35% width):
  â€¢ Image upload button
  â€¢ Image preview area (600Ã—600)
  â€¢ Clear button

Right Panel (65% width - DOMINANT):
  â€¢ Large RED "ANALYZE LEAF" button
  â€¢ Results display:
    - Disease name (RED, highlighted)
    - Confidence % (GREEN, highlighted)
    - Severity level (color-coded)
    - Type & description
    - Treatment recommendations
    - Prevention strategies
    - All 8 predictions ranked

Color Scheme:
  â€¢ Dark background (#0a0e27)
  â€¢ Neon green header (#00d084)
  â€¢ Red accent button (#ff6b6b)
  â€¢ Blue results panel (#192847)
"""
print(gui)

# How to Run
print("\nğŸš€ HOW TO RUN")
print("-" * 70)
run_steps = """
Step 1: Open PowerShell in project folder

Step 2: Activate virtual environment
  .\.venv\Scripts\Activate.ps1

Step 3: Run the app
  python mango_ui_best.py

Step 4: Use the GUI
  1. Click "Choose Image"
  2. Select a mango leaf photo
  3. Click "ANALYZE LEAF"
  4. View disease, confidence, and treatment
"""
print(run_steps)

# Common Viva Questions
print("\nâ“ LIKELY VIVA QUESTIONS & ANSWERS (1 min each)")
print("-" * 70)

questions = {
    "Q1: Why Swin Transformer?": 
        "A: Modern vision transformer with hierarchical windows, efficient attention, and strong ImageNet pretrained weights perfect for transfer learning on small datasets.",
    
    "Q2: Why two-phase training?":
        "A: Phase 1 trains only the head with frozen backbone to adapt to our 8 classes. Phase 2 unfreezes and fine-tunes the backbone slowly with low learning rate to preserve pretrained features.",
    
    "Q3: How did you avoid overfitting?":
        "A: Used data augmentation (flip, rotate, zoom, contrast, brightness), L2 regularization, dropout layers, batch normalization, and early stopping on validation accuracy.",
    
    "Q4: What is temperature scaling in the GUI?":
        "A: Post-hoc calibration technique applied at inference to sharpen softmax probabilities, making confidence scores more interpretable for display (T=0.15).",
    
    "Q5: How does inference work in GUI?":
        "A: Rebuild model architecture, load weights from .h5 file (avoids custom layer issues), preprocess image to 224Ã—224 without normalization (model handles it), predict softmax, apply temperature scaling, display top class and confidence.",
    
    "Q6: What was the biggest challenge?":
        "A: Initial accuracy was low (33%) because EPOCHS=1. Fixed by increasing to 60 epochs (30+30), adding augmentation, and matching preprocessing between training and inference.",
    
    "Q7: How would you improve the model?":
        "A: More diverse training data, class balancing, hyperparameter tuning (batch size, learning rate), ensemble models, or better calibration methods like Platt scaling.",
    
    "Q8: Can this be deployed?":
        "A: Yes, with FastAPI/Flask for web API, or TFServing for production. Current GUI is desktop demo. Would need load balancing, monitoring, and retraining pipeline for real deployment."
}

for q, a in questions.items():
    print(f"\n{q}")
    print(f"{a}")

# Dataset Path
print("\n\nğŸ“ IMPORTANT PATHS")
print("-" * 70)
paths = """
Dataset Location:
  C:\Users\ajayd\Downloads\MangDisease

Saved Model Location:
  saved_models/7/
    â”œâ”€â”€ model.keras
    â”œâ”€â”€ model_weights.weights.h5
    â””â”€â”€ metadata.json

Project Files:
  â”œâ”€â”€ swintin_executed.ipynb    (Training notebook)
  â”œâ”€â”€ mango_ui_best.py          (GUI application)
  â”œâ”€â”€ requirements.txt          (Dependencies)
  â””â”€â”€ README.md                 (Full documentation)
"""
print(paths)

# Final Tips
print("\nğŸ’¡ VIVA TIPS")
print("-" * 70)
tips = """
âœ“ Know the dataset path and class names
âœ“ Be ready to explain two-phase training (why freeze, why unfreeze)
âœ“ Have one bug you fixed ready to discuss (e.g., double normalization or model loading)
âœ“ Understand why temperature scaling helps with confidence display
âœ“ Be able to run the GUI and explain what happens when you click buttons
âœ“ Know the exact accuracy numbers (99.87% val, 100% test)
âœ“ Explain how transfer learning helps with limited data
âœ“ Be ready to discuss trade-offs (accuracy vs speed, complexity vs interpretability)
"""
print(tips)

print("\n" + "=" * 70)
print("âœ… You're ready! Good luck with your viva! ğŸŒ¿")
print("=" * 70)
